{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langdetect\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/59/4bc44158a767a6d66de18c4136c8aa90491d56cc951c10b74dd1e13213c9/langdetect-1.0.7.zip (998kB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.0MB 13.7MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /Users/arushi/anaconda3/lib/python3.7/site-packages (from langdetect) (1.12.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Running setup.py bdist_wheel for langdetect ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/arushi/Library/Caches/pip/wheels/ec/0c/a9/1647275e7ef5014e7b83ff30105180e332867d65e7617ddafe\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect\n",
      "Successfully installed langdetect-1.0.7\n"
     ]
    }
   ],
   "source": [
    "!pip install langdetect\n",
    "!wget https://dumps.wikimedia.org/other/contenttranslation/20191101/cx-corpora._2ja.html.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import fasttext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = ('cx-corpora._2ja.html 2.json')\n",
    "\n",
    "with open(file, encoding='utf-8') as f:\n",
    "    d = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for line in d:\n",
    "    if line['sourceLanguage'] == 'es' and line['targetLanguage'] == 'ja':\n",
    "        if detect(line['source']['content']) == 'es' and detect(line['target']['content']) == 'ja': #without this check it's 900 records\n",
    "            try:\n",
    "                source = unicodedata.normalize('NFKC',line['source']['content'])\n",
    "                target = unicodedata.normalize('NFKC',line['target']['content'])\n",
    "                if not source == '' and not target == '':\n",
    "                    data.append([source,target])\n",
    "            except TypeError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code to split train and test\n",
    "df = pd.DataFrame(data,columns = ['source','target'])\n",
    "# train, test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
