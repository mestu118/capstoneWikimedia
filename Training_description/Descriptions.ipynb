{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dOq1yuJ--zZD"
   },
   "outputs": [],
   "source": [
    "# # !gunzip cx-corpora.en2es.text.json.gz\n",
    "# !pip install --user pybind11\n",
    "# !pip install fasttext\n",
    "#!conda install -c conda-forge fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_w7cb_2j_U-S"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import fasttext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from numpy.core.umath_tests import inner1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/ah3243/.conda/envs/capstone/lib/python3.6/site-packages (4.36.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UsecK2xOBInn"
   },
   "outputs": [],
   "source": [
    "def apply_transform(vec, transform):\n",
    "    \"\"\"\n",
    "    Apply the given transformation to the vector space\n",
    "\n",
    "    Right-multiplies given transform with embeddings E:\n",
    "        E = E * transform\n",
    "\n",
    "    Transform can either be a string with a filename to a\n",
    "    text file containing a ndarray (compat. with np.loadtxt)\n",
    "    or a numpy ndarray.\n",
    "    \"\"\"\n",
    "    transmat = np.loadtxt(transform)# if isinstance(transform, str) else transform\n",
    "    return np.matmul(vec, transmat)\n",
    "\n",
    "def make_training_matrices(source_dictionary, target_dictionary, bilingual_dictionary):\n",
    "    \"\"\"\n",
    "    Source and target dictionaries are the FastVector objects of\n",
    "    source/target languages. bilingual_dictionary is a list of \n",
    "    translation pair tuples [(source_word, target_word), ...].\n",
    "    \"\"\"\n",
    "    source_matrix = []\n",
    "    target_matrix = []\n",
    "    \n",
    "    len_bd = len(bilingual_dictionary)\n",
    "\n",
    "    for i, (source, target) in tqdm(enumerate(bilingual_dictionary)):\n",
    "#         tqdm(f'\\r{i + 1}/{len_bd} | {100 * (i + 1) / len_bd:.3f} %', end = '', flush = True)\n",
    "        sourceVector = source_dictionary.get_sentence_vector(source.lower().strip().replace('_',' '))\n",
    "        targetVector = target_dictionary.get_sentence_vector(target.lower().strip().replace('_',' '))\n",
    "        source_matrix.append(sourceVector)\n",
    "        target_matrix.append(targetVector)\n",
    "        \n",
    "    # return training matrices\n",
    "    return np.array(source_matrix), np.array(target_matrix)\n",
    "\n",
    "def normalized(a, axis=-1, order=2):\n",
    "    \"\"\"Utility function to normalize the rows of a numpy array.\"\"\"\n",
    "    l2 = np.atleast_1d(np.linalg.norm(a, order, axis))\n",
    "    l2[l2 == 0] = 1\n",
    "    return a / np.expand_dims(l2, axis)\n",
    "\n",
    "\n",
    "def learn_transformation(source_matrix, target_matrix, normalize_vectors=True):\n",
    "    \"\"\"\n",
    "    Source and target matrices are numpy arrays, shape\n",
    "    (dictionary_length, embedding_dimension). These contain paired\n",
    "    word vectors from the bilingual dictionary.\n",
    "    \"\"\"\n",
    "    # optionally normalize the training vectors\n",
    "    if normalize_vectors:\n",
    "        source_matrix = normalized(source_matrix)\n",
    "        target_matrix = normalized(target_matrix)\n",
    "\n",
    "    # perform the SVD\n",
    "    product = np.matmul(target_matrix.transpose(), source_matrix)\n",
    "    U, s, V = np.linalg.svd(product)\n",
    "\n",
    "    # return orthogonal transformation which aligns source language to the target\n",
    "    return np.matmul(U, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pdgQ31teCXWm"
   },
   "outputs": [],
   "source": [
    "# file = ('cx-corpora.en2es.text.json')\n",
    "\n",
    "# with open(file, encoding='utf-8') as f:\n",
    "#     d = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ui-6W_80LmE6",
    "outputId": "7b1782dd-da10-4bcd-ac91-cb1fc207862a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = {}\n",
    "model['en'] = fasttext.load_model('wiki.en.bin')\n",
    "model['es'] = fasttext.load_model('wiki.es.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('descriptions_final.csv', error_bad_lines=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('descriptions_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source_language</th>\n",
       "      <th>source_value</th>\n",
       "      <th>target_language</th>\n",
       "      <th>target_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>how the player was acquired; qualifier for P54...</td>\n",
       "      <td>es</td>\n",
       "      <td>forma en que fue adquirido el jugador; calific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>rivers and other outflows waterway names. If e...</td>\n",
       "      <td>es</td>\n",
       "      <td>río que drena el lago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>en</td>\n",
       "      <td>amount of goods and services bought from other...</td>\n",
       "      <td>es</td>\n",
       "      <td>cantidad de bienes y servicios comprados a otr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>en</td>\n",
       "      <td>Wikimedia list related to this subject</td>\n",
       "      <td>es</td>\n",
       "      <td>lista de Wikimedia para el elemento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>en</td>\n",
       "      <td>identifier for a unique bibliographic record i...</td>\n",
       "      <td>es</td>\n",
       "      <td>número de control del Online Computer Library ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 source_language  \\\n",
       "0           0              en   \n",
       "1           1              en   \n",
       "2           2              en   \n",
       "3           3              en   \n",
       "4           4              en   \n",
       "\n",
       "                                        source_value target_language  \\\n",
       "0  how the player was acquired; qualifier for P54...              es   \n",
       "1  rivers and other outflows waterway names. If e...              es   \n",
       "2  amount of goods and services bought from other...              es   \n",
       "3             Wikimedia list related to this subject              es   \n",
       "4  identifier for a unique bibliographic record i...              es   \n",
       "\n",
       "                                        target_value  \n",
       "0  forma en que fue adquirido el jugador; calific...  \n",
       "1                              río que drena el lago  \n",
       "2  cantidad de bienes y servicios comprados a otr...  \n",
       "3                lista de Wikimedia para el elemento  \n",
       "4  número de control del Online Computer Library ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "666870"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = []\n",
    "for source, target in zip(data['source_value'], data['target_value']):\n",
    "    try:\n",
    "        source_cleaned = unicodedata.normalize('NFD', source)\n",
    "        target_cleaned = unicodedata.normalize('NFD', target)\n",
    "        if not source == ''  and not target == '':\n",
    "            data_cleaned.append([source_cleaned, target_cleaned])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "666867"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QXesC2HkEN5q"
   },
   "outputs": [],
   "source": [
    "## Code to split train and test\n",
    "df = pd.DataFrame(data_cleaned,columns = ['source','target'])\n",
    "# train, test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('description_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.to_csv('content_trans_test.csv',index=False)\n",
    "# train.to_csv('content_trans_train.csv',index=False)\n",
    "test = pd.read_csv('../ContentTranslation/content_test.csv') #same for everyone\n",
    "train = pd.read_csv('description_train.csv') #replace with your respective dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JciKTIkqD30a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "666867it [01:24, 7873.06it/s]\n"
     ]
    }
   ],
   "source": [
    "#Train\n",
    "bilingual_dictionary = list(zip(train['source'],train['target']))\n",
    "source_matrix, target_matrix = make_training_matrices(model['en'], model['es'], bilingual_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = learn_transformation(source_matrix, target_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('description_trans_transform_en_es.txt', transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before trans: 0.01143723951168304\n"
     ]
    }
   ],
   "source": [
    "print(\"Before trans:\", np.mean(inner1d(target_matrix, source_matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After trans: 0.32593447005301746\n"
     ]
    }
   ],
   "source": [
    "print(\"After trans:\", np.mean(inner1d(target_matrix, np.matmul(transform, source_matrix.T).T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "72972it [01:28, 821.72it/s] \n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "bilingual_dictionary = list(zip(test['source'],test['target']))\n",
    "source_matrix_test, target_matrix_test = make_training_matrices(model['en'], model['es'], bilingual_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before trans: 0.0010129306058742473\n",
      "After trans: 0.264224146733514\n"
     ]
    }
   ],
   "source": [
    "#before\n",
    "print(\"Before trans:\",np.mean(inner1d(target_matrix_test, source_matrix_test)))\n",
    "#after\n",
    "print(\"After trans:\", np.mean(inner1d(target_matrix_test, np.matmul(transform, source_matrix_test.T).T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Content Translation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
