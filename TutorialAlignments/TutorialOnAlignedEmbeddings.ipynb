{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to cross-lingual word-embeddings at Wikimania 2019\n",
    "\n",
    "* In this tutorial we will learn how to work with cross-lingual word embeddings. \n",
    "* See introduction [slides here](https://upload.wikimedia.org/wikipedia/commons/6/63/Tutorial_on_Multilingual_Word_Embeddings%2C_Wikimania_2019.pdf)\n",
    "* This code is based on the repository shared by [Smith et al](https://github.com/Babylonpartners/fastText_multilingual)\n",
    "* You can see applications of these code on the Wikipedia [Sections](https://github.com/digitalTranshumant/wmf-interlanguage) and [Template parameters](https://github.com/digitalTranshumant/templatesAlignment) alignments.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es\n"
     ]
    }
   ],
   "source": [
    "#Config \n",
    "## Add here your folders and languages\n",
    "import fasttext as fastText\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "lang1 = 'en'\n",
    "lang2 = 'es'\n",
    "langs =[lang1,lang2]\n",
    "pathVectors = 'vectors' \n",
    "pathAlignment = 'wikiAlignments/'\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download fasttext models\n",
    "\n",
    "* This script download the fasttext pre-trained models in the languages listed langs variable.\n",
    "* This process **can take long time**.\n",
    "* Note that **each model file is around 8G** , and later you will need to unzip those models, using around 15G per model in total.\n",
    "* Comment (add # prefix)the first line in the next cell to download the models. If you already have the models you in your folder, you can skip this step. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: vectors/: File exists\n",
      "en\n",
      "--2019-09-26 15:46:30--  https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.en.zip\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.6.166, 104.20.22.166\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.6.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10356881291 (9.6G) [application/zip]\n",
      "Saving to: ‘vectors/wiki.en.zip’\n",
      "\n",
      "wiki.en.zip         100%[===================>]   9.65G  2.96MB/s    in 58m 22s \n",
      "\n",
      "2019-09-26 16:44:53 (2.82 MB/s) - ‘vectors/wiki.en.zip’ saved [10356881291/10356881291]\n",
      "\n",
      "es\n",
      "--2019-09-26 16:44:53--  https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.es.zip\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.6.166, 104.20.22.166\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.6.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5445405108 (5.1G) [application/zip]\n",
      "Saving to: ‘vectors/wiki.es.zip’\n",
      "\n",
      "wiki.es.zip          42%[=======>            ]   2.17G  2.64MB/s    in 16m 23s \n",
      "\n",
      "2019-09-26 19:38:01 (2.26 MB/s) - Read error at byte 2327299513/5445405108 (Success). Retrying.\n",
      "\n",
      "--2019-09-26 19:38:02--  (try: 2)  https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.es.zip\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.6.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 206 Partial Content\n",
      "Length: 5445405108 (5.1G), 3118105595 (2.9G) remaining [application/zip]\n",
      "Saving to: ‘vectors/wiki.es.zip’\n",
      "\n",
      "wiki.es.zip          71%[++++++++=====>      ]   3.64G   927KB/s    in 24m 46s \n",
      "\n",
      "2019-09-26 20:34:03 (1.01 MB/s) - Read error at byte 3906517854/5445405108 (Success). Retrying.\n",
      "\n",
      "--2019-09-26 20:34:05--  (try: 3)  https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.es.zip\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.6.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 206 Partial Content\n",
      "Length: 5445405108 (5.1G), 1538887254 (1.4G) remaining [application/zip]\n",
      "Saving to: ‘vectors/wiki.es.zip’\n",
      "\n",
      "wiki.es.zip         100%[++++++++++++++=====>]   5.07G  1.01MB/s    in 21m 22s \n",
      "\n",
      "2019-09-26 20:55:27 (1.15 MB/s) - ‘vectors/wiki.es.zip’ saved [5445405108/5445405108]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# COMMENT  HERE TO RUN THIS CELL\n",
    "\n",
    "!mkdir {pathVectors}\n",
    "for l in langs:\n",
    "    print(l)\n",
    "    !wget -P vectors/ {'https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.%s.zip' % l}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load the models, this can take few minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectors/wiki.es.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = {}\n",
    "print('%s/wiki.%s.bin' % (pathVectors,lang))\n",
    "\n",
    "for lang in langs:\n",
    "    model[lang] = fasttext.load_model('%s/wiki.%s.bin' % (pathVectors,lang))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings example\n",
    "\n",
    "* This is how a cat looks like for this embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03272143,  0.03321843, -0.0772398 ,  0.02752271, -0.04689749,\n",
       "        0.10779523,  0.05039032, -0.1213629 ,  0.00796918,  0.0365316 ,\n",
       "        0.03590076, -0.00070022,  0.04651386, -0.04166288,  0.06664581,\n",
       "       -0.02164455,  0.0180805 , -0.10384931,  0.04688571,  0.06662694,\n",
       "        0.00233572,  0.12208793, -0.09872068,  0.0255165 ,  0.08340995,\n",
       "        0.00577335, -0.0176113 ,  0.06296295,  0.07984982,  0.11208957,\n",
       "        0.06389221,  0.05539172,  0.02762271, -0.05251925,  0.04438546,\n",
       "       -0.02399754, -0.01537215, -0.01010495,  0.01509995, -0.00657111,\n",
       "       -0.02613736, -0.061927  , -0.05292661, -0.00875183,  0.03022415,\n",
       "        0.12282077, -0.01940934, -0.09258875,  0.03871215, -0.06963187,\n",
       "        0.02200041, -0.01411154, -0.02184908, -0.08269455,  0.07468157,\n",
       "        0.08944456,  0.00224687, -0.1002942 ,  0.01784089,  0.04561058,\n",
       "        0.04928856, -0.11202534,  0.02219844,  0.05074738, -0.01451611,\n",
       "       -0.08938298,  0.02949806, -0.00669799, -0.03016053,  0.01116755,\n",
       "       -0.01216495, -0.08206985,  0.05887382, -0.09758892, -0.09325767,\n",
       "        0.00637048, -0.03989533,  0.08270881, -0.08843972,  0.02818453,\n",
       "       -0.01623796,  0.00295207,  0.04470299,  0.08739536,  0.08489413,\n",
       "        0.02700518, -0.03938108,  0.01117819,  0.05708639,  0.01493074,\n",
       "        0.02871869, -0.0460449 ,  0.08188171,  0.03403811,  0.0253881 ,\n",
       "        0.03618389, -0.06597117, -0.05926748, -0.06118818,  0.01171021,\n",
       "        0.04180083,  0.01997853, -0.05869597,  0.02966375,  0.00966474,\n",
       "       -0.05524473,  0.05189364,  0.00175703,  0.06135704, -0.04616855,\n",
       "        0.04846644, -0.00707582, -0.07514237, -0.0123611 ,  0.01133362,\n",
       "       -0.03663448,  0.02257092, -0.04623863,  0.03583612, -0.03202283,\n",
       "       -0.00960319, -0.03316909,  0.01221914,  0.05684921,  0.03675234,\n",
       "        0.03050192,  0.12296707,  0.00666069,  0.07358187,  0.11613067,\n",
       "       -0.07004147,  0.03517091, -0.06014191,  0.07283556,  0.00640122,\n",
       "       -0.02515739,  0.03471669, -0.03982008, -0.10447585,  0.07287212,\n",
       "        0.02370786,  0.02260983,  0.04698145,  0.02574782, -0.01695139,\n",
       "        0.03451049, -0.00160255, -0.04570806, -0.00442773,  0.06822422,\n",
       "       -0.03121714, -0.06248022, -0.10695268, -0.03090054,  0.03447342,\n",
       "        0.02105642,  0.0607292 , -0.02616017, -0.00337311,  0.07103202,\n",
       "        0.02983532,  0.00761606, -0.06654347,  0.03866716,  0.02840243,\n",
       "       -0.0489554 , -0.03658335, -0.0551444 ,  0.02579325,  0.03210133,\n",
       "       -0.01313129, -0.11777922, -0.02994463, -0.0203511 ,  0.03932046,\n",
       "       -0.00641337, -0.01978315, -0.08679112,  0.011424  , -0.04906217,\n",
       "       -0.0420751 , -0.06741455,  0.11509562, -0.07564392, -0.01490594,\n",
       "       -0.0023952 ,  0.00916727, -0.0159545 ,  0.01070366,  0.10338525,\n",
       "       -0.0020056 , -0.08471239, -0.00999477,  0.08227528, -0.08288687,\n",
       "       -0.12098601, -0.10805968, -0.07567748, -0.18051523, -0.03994304,\n",
       "        0.02763269,  0.02266109,  0.02570431,  0.0088365 ,  0.0036729 ,\n",
       "       -0.15515535, -0.00287875, -0.14432205, -0.05114172, -0.06278293,\n",
       "        0.04720113, -0.05614552,  0.04631633, -0.03025362,  0.05448557,\n",
       "       -0.02011943,  0.08389292, -0.00492832, -0.05356852, -0.03316532,\n",
       "       -0.01693997, -0.05033619, -0.12712255,  0.05866379, -0.03195552,\n",
       "       -0.02060165, -0.03451328, -0.00604885,  0.03508535,  0.05694634,\n",
       "        0.03188653,  0.06038615, -0.01133399, -0.01042211,  0.0121483 ,\n",
       "        0.08726177, -0.05743813,  0.03939461, -0.01587104,  0.06706464,\n",
       "       -0.01761667,  0.10062715,  0.07246886,  0.07961714, -0.00538224,\n",
       "        0.00322489, -0.05657806,  0.06032568, -0.0502349 ,  0.12738235,\n",
       "        0.02816762, -0.06601696, -0.1240452 ,  0.0627571 ,  0.02809147,\n",
       "       -0.05813975,  0.04783763, -0.01850602,  0.07075618, -0.05448457,\n",
       "       -0.0044456 ,  0.01098599,  0.01625209, -0.05261958, -0.09557738,\n",
       "       -0.01058379,  0.01890603,  0.00663763,  0.01644058, -0.0195105 ,\n",
       "       -0.04809193, -0.01746241,  0.09031167, -0.09797578,  0.00398914,\n",
       "       -0.14198521, -0.00375971, -0.06100339,  0.08657616,  0.06276353,\n",
       "        0.08580878,  0.01758965,  0.07664976,  0.03455459,  0.09488834,\n",
       "        0.01922096,  0.00618542,  0.04868407, -0.1054813 , -0.03341939,\n",
       "        0.03595594, -0.07743388,  0.02431411, -0.01262254, -0.01633173,\n",
       "       -0.00156663, -0.01580206,  0.06468589,  0.12313337, -0.00206504],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['en'].get_sentence_vector('cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Remember that **those number doesn't have a meaning by themselves**, and will change if you retrain your model in other corpus. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(model['en'].get_sentence_vector('cat')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distances within the same language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5402991771697998"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = model['en'].get_sentence_vector('cat')\n",
    "v2 = model['en'].get_sentence_vector('kitty')\n",
    "distance.cosine(v1,v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6383496820926666"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = model['en'].get_sentence_vector('cat')\n",
    "v2 = model['en'].get_sentence_vector('lion')\n",
    "distance.cosine(v1,v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8043883889913559"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = model['en'].get_sentence_vector('cat')\n",
    "v2 = model['en'].get_sentence_vector('car')\n",
    "distance.cosine(v1,v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load transformation Matrices\n",
    "* Note that his repository already contains transformation from 'en' to 'es'\n",
    "* This alignments are generated using [this code](https://analytics.wikimedia.org/datasets/one-off/dsaez/)\n",
    "* If you need to a pair of languages that is not contained here, please contact us, or use the pre-trained [provided here](https://drive.google.com/drive/folders/1_cbl3GKmg9Ots6_QOXcGxRNQr8SCELWO?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = model['es'].get_sentence_vector('perro')\n",
    "v2 = model['en'].get_sentence_vector('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9362809807062149"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.cosine(v1,v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The following function apply the transformation to a given vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transform(vec, transform):\n",
    "        \"\"\"\n",
    "        Apply the given transformation to the vector space\n",
    "\n",
    "        Right-multiplies given transform with embeddings E:\n",
    "            E = E * transform\n",
    "\n",
    "        Transform can either be a string with a filename to a\n",
    "        text file containing a ndarray (compat. with np.loadtxt)\n",
    "        or a numpy ndarray.\n",
    "        \"\"\"\n",
    "        transmat = np.loadtxt(transform) if isinstance(transform, str) else transform\n",
    "        return np.matmul(vec, transmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align second language\n",
    "v2Aligned = apply_transform(v2,'%s/apply_in_%s_to_%s.txt' % (pathAlignment,'en','es') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29473989976649984"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.cosine(v1,v2Aligned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subword information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using subword information with modified or misspelled words\n",
    "\n",
    "within the same language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4250869154930115"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = model['en'].get_sentence_vector('excellent')\n",
    "v2 = model['en'].get_sentence_vector('excelent')\n",
    "distance.cosine(v1,v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or with cross-lingual aligned vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4684736197488095"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = model['es'].get_sentence_vector('perro1')\n",
    "v2 = model['en'].get_sentence_vector('dog')\n",
    "v2Aligned = apply_transform(v2,'%s/apply_in_%s_to_%s.txt' % (pathAlignment,'en','es') )\n",
    "distance.cosine(v1,v2Aligned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = model['es'].get_sentence_vector('Hola! Que tenga un bonito día señor, nos vemos más tarde! :)')\n",
    "sentence2 = model['en'].get_sentence_vector('Hi! Have a nice day sir, see you later! :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9927418855950236"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.cosine(sentence1,sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence2Aligned = apply_transform(sentence2,'%s/apply_in_%s_to_%s.txt' % (pathAlignment,'en','es') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44225135145721073"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.cosine(sentence1,sentence2Aligned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligning  sets of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\n",
      "es\n"
     ]
    }
   ],
   "source": [
    "transmat = {}\n",
    "for lang in langs:\n",
    "    print(lang)\n",
    "    transmat[lang] = {}\n",
    "    for lang2 in langs:\n",
    "        if lang!=lang2:\n",
    "            transmat[lang][lang2] = np.loadtxt('%s/apply_in_%s_to_%s.txt' % (pathAlignment,lang2,lang))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = {}\n",
    "words[lang1] = ['cat','kitty','motocycle','car','dog','truck','geography','mountains','rivers','basketball','football']\n",
    "words[lang2] = ['gato','automóvil','perro','camión','geografía','montañas','rios','baloncesto','futbol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMoreSimilar(wordLang1,setLang2,sourceLang,targetLang):\n",
    "    \"\"\"\n",
    "    Given a word in language 1 and set of words/sentences language 2\n",
    "    return \n",
    "    wordLang1: str, 'perro'\n",
    "    set2: dict or list, ['hello','dog']\n",
    "    sourceLang: str, 'es'\n",
    "    targetLang: str, 'en'\n",
    "    return list\n",
    "    \"\"\"\n",
    "    global model\n",
    "    global transmat\n",
    "    d = []\n",
    "    vec1 = model[sourceLang].get_sentence_vector(wordLang1)\n",
    "    for s2 in setLang2:\n",
    "        vec2 = model[targetLang].get_sentence_vector(s2.strip().replace('_',' '))\n",
    "        vec2T = apply_transform(vec2,transmat[sourceLang][targetLang])\n",
    "        dist = distance.cosine(vec1,vec2T)\n",
    "        d.append((dist,s2))\n",
    "    return sorted(d)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for the most similar word to: cat\n",
      "list ['gato', 'automóvil', 'perro', 'camión', 'geografía', 'montañas', 'rios', 'baloncesto', 'futbol']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4377602546993745, 'gato')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordEn ='cat'\n",
    "print('Searching for the most similar word to:', wordEn)\n",
    "print('list',words['es'])\n",
    "getMoreSimilar(wordEn,words['es'],'en','es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for the most similar word: kitty\n",
      "list ['gato', 'automóvil', 'perro', 'camión', 'geografía', 'montañas', 'rios', 'baloncesto', 'futbol']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6476671722893668, 'gato')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordEn ='kitty'\n",
    "print('Searching for the most similar word:', wordEn)\n",
    "print('list',words['es'])\n",
    "getMoreSimilar(wordEn,words['es'],'en','es')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aligning set of words\n",
    "\n",
    "Given two sets of words, get a mapping one-to-one mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-to-one mappings\n",
    "def alignSets(set1,set2,sourceLang,targetLang,sensivity=.45):\n",
    "    \"\"\"\n",
    "    Given two sets of words/sentences in two languages\n",
    "    return the possible alignments between sentences\n",
    "    set1: dict or list, ['hola','perro']\n",
    "    set2: dict or list, ['hello','dog']\n",
    "    sourceLang: str, 'es'\n",
    "    targetLang: str, 'en'\n",
    "    return list\n",
    "    \"\"\"\n",
    "    global model\n",
    "    global transmat\n",
    "    output = []\n",
    "    G= nx.Graph()\n",
    "    for s1 in set1:\n",
    "        vec1 = model[sourceLang].get_sentence_vector(s1.strip().replace('_',' '))\n",
    "        for s2 in set2:\n",
    "                    vec2= model[targetLang].get_sentence_vector(s2.strip().replace('_',' '))\n",
    "                    vec2T = apply_transform(vec2,transmat[sourceLang][targetLang])\n",
    "                    dist = distance.cosine(vec1,vec2T)\n",
    "                    if dist < sensivity:\n",
    "                        node1= '%s_%s' % (sourceLang,s1)\n",
    "                        node2= '%s_%s' % (targetLang,s2)\n",
    "                        G.add_edge(node1,node2)\n",
    "                        G[node1][node2]['w'] = dist\n",
    "\n",
    "                \n",
    "    while G.edges():\n",
    "            p = sorted(G.edges(data=True), key=lambda x: x[2]['w'])[0]\n",
    "            psorted = sorted(list(p[:2]))\n",
    "            output.append({psorted[0][:2]:psorted[0][3:],psorted[1][:2]:psorted[1][3:],'d':p[2]['w']})\n",
    "            G.remove_node(p[0])\n",
    "            G.remove_node(p[1])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'kitty', 'motocycle', 'car', 'dog', 'truck', 'geography', 'mountains', 'rivers', 'basketball', 'football']\n",
      "['gato', 'automóvil', 'perro', 'camión', 'geografía', 'montañas', 'rios', 'baloncesto', 'futbol']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'en': 'basketball', 'es': 'baloncesto', 'd': 0.20396930125846902},\n",
       " {'en': 'mountains', 'es': 'montañas', 'd': 0.24248148366015954},\n",
       " {'en': 'truck', 'es': 'camión', 'd': 0.2715019349251284},\n",
       " {'en': 'car', 'es': 'automóvil', 'd': 0.274432416258372},\n",
       " {'en': 'geography', 'es': 'geografía', 'd': 0.2938059612477104},\n",
       " {'en': 'dog', 'es': 'perro', 'd': 0.29473989749777796},\n",
       " {'en': 'football', 'es': 'futbol', 'd': 0.39243692824605925},\n",
       " {'en': 'cat', 'es': 'gato', 'd': 0.4377602546993745}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(words[lang1])\n",
    "print(words[lang2])\n",
    "\n",
    "alignSets(words[lang1],words[lang2],lang1,lang2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
